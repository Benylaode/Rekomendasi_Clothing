# -*- coding: utf-8 -*-
"""Sistem Rekomendasi Pakaian Berbasis Konten (Diperbarui)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LonN-czwFZuw21TCRrL86yRd6uMKbg0f
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re
import string
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud

"""# --- 1. Data Understanding ---
# Memuat dataset
# Asumsikan file CSV berada di direktori yang sama atau path yang sesuai
"""

try:
    df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv', index_col=0)
    print("Dataset berhasil dimuat.")
except FileNotFoundError:
    print("Error: File 'Women_Clothing_E-Commerce_Reviews.csv' tidak ditemukan.")
    print("Pastikan file dataset berada di direktori yang sama dengan notebook ini.")
    exit() # Keluar jika file tidak ditemukan

print("\n--- Tampilan Awal Dataset ---")
print(df.head())

print("\n--- Informasi Dataset ---")
df.info()

print(f"\nDimensi Dataset: {df.shape[0]} baris, {df.shape[1]} kolom")

print("\n--- Statistik Deskriptif ---")
print(df.describe())

print("\n--- Cek Missing Values Awal ---")
print(df.isnull().sum())

print("\n--- Jumlah Nilai Unik per Kolom ---")
print(df.nunique())

"""Dataset ini berisi 23.486 ulasan pelanggan produk fashion, mencakup usia, ulasan teks, rating, dan apakah produk direkomendasikan. Terdapat kombinasi fitur numerik dan kategorikal, dengan beberapa nilai hilang di kolom `Title`, `Review Text`, dan kategori produk. Sebagian besar rating tinggi dan ulasan bersifat positif, menunjukkan kecenderungan pengguna untuk merekomendasikan produk.

--- Visualisasi Data untuk Pemahaman Konsep (EDA) ---
"""

plt.style.use('seaborn-v0_8-darkgrid')
plt.rcParams['figure.figsize'] = (10, 6)

plt.figure(figsize=(8, 5))
sns.countplot(x='Rating', data=df, palette='viridis')
plt.title('Distribusi Rating Produk')
plt.xlabel('Rating Bintang')
plt.ylabel('Jumlah Produk')
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(y='Division Name', data=df, order=df['Division Name'].value_counts().index, palette='plasma')
plt.title('Distribusi Produk Berdasarkan Nama Divisi')
plt.xlabel('Jumlah Produk')
plt.ylabel('Nama Divisi')
plt.show()

plt.figure(figsize=(12, 7))
sns.countplot(y='Department Name', data=df, order=df['Department Name'].value_counts().index, palette='magma')
plt.title('Distribusi Produk Berdasarkan Nama Departemen')
plt.xlabel('Jumlah Produk')
plt.ylabel('Nama Departemen')
plt.show()

plt.figure(figsize=(12, 8))
top_classes = df['Class Name'].value_counts().head(15).index
sns.countplot(y='Class Name', data=df[df['Class Name'].isin(top_classes)], order=top_classes, palette='cividis')
plt.title('Distribusi Produk Berdasarkan Nama Kelas (Top 15)')
plt.xlabel('Jumlah Produk')
plt.ylabel('Nama Kelas')
plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(df['Age'].dropna(), bins=30, kde=True, color='skyblue')
plt.title('Distribusi Usia Pelanggan')
plt.xlabel('Usia')
plt.ylabel('Frekuensi')
plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(df['Positive Feedback Count'].dropna(), bins=30, kde=True, color='lightcoral')
plt.title('Distribusi Jumlah Umpan Balik Positif')
plt.xlabel('Jumlah Umpan Balik Positif')
plt.ylabel('Frekuensi')
plt.show()

temp_review_text = df['Review Text'].fillna('').astype(str)
long_string = ','.join(list(temp_review_text.values))
wordcloud = WordCloud(background_color="white", max_words=500, contour_width=3, contour_color='steelblue', collocations=False)
wordcloud.generate(long_string)
plt.figure(figsize=(10, 7))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.title('Word Cloud dari Teks Ulasan')
plt.show()

"""bisa dilihat dari hasl visualisasi di atas menunjukan bawah data memiliki beberapa favorit data seperti jumlah dress yang banyak peminatnya dan juga rentang usia pembelajang yang mayoritas 30-60 ke atas,  dan juga secara konsep jenis barang yang paling banyak direview adalah dress yang berasal dari departemen dereses, ini menunjukan bahwa sebagian besar data itu melakukan review terhadap dress. dan kata yang paling seliring mucnul jjuga adalah dress

# --- 2. Data Preparation ---

# --- 2.1. Menangani Data Duplikat ---
dengan melakukan drop duplikat
"""

print("\n--- Menangani Data Duplikat ---")
initial_rows = df.shape[0]
df.drop_duplicates(inplace=True)
rows_after_duplicates = df.shape[0]
print(f"Jumlah baris sebelum menghapus duplikat: {initial_rows}")
print(f"Jumlah baris setelah menghapus duplikat: {rows_after_duplicates}")
print(f"Jumlah duplikat yang dihapus: {initial_rows - rows_after_duplicates}")

"""# --- 2.2. Menangani Missing Values (NaN/Null) ---
data yang bersifat numerik saya berikan isi dengan rata-rata dan review teks dengan teks kosong karena bersifat bias jika diisi secara tidak baik
"""

for col in ['Age', 'Positive Feedback Count']:
    if df[col].isnull().any():
        mean_val = df[col].mean()
        df[col].fillna(mean_val, inplace=True)
        print(f"Kolom '{col}' NaN diisi dengan rata-rata: {mean_val:.2f}")

if df['Review Text'].isnull().any():
    df['Review Text'] = df['Review Text'].fillna('')
    print("Kolom 'Review Text' NaN diisi dengan string kosong.")

for col in ['Division Name', 'Department Name', 'Class Name']:
    if df[col].isnull().any():
        df[col] = df[col].fillna('unknown')
        print(f"Kolom '{col}' NaN diisi dengan 'unknown'.")

print("\n--- Cek Missing Values Setelah Penanganan ---")
print(df.isnull().sum())

"""# --- 2.3. Menangani Outlier dengan Metode IQR (Interquartile Range) ---"""

numerical_cols = ['Age', 'Positive Feedback Count', 'Rating']
for col in numerical_cols:
    if pd.api.types.is_numeric_dtype(df[col]):
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers_count = df[(df[col] < lower_bound) | (df[col] > upper_bound)].shape[0]
        print(f"Kolom '{col}': {outliers_count} outlier teridentifikasi.")


        df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])
        df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])
        print(f"Outlier pada kolom '{col}' telah di-capping.")
    else:
        print(f"Kolom '{col}' bukan tipe numerik, outlier tidak ditangani.")

print("\n--- Statistik Deskriptif Setelah Penanganan Outlier ---")
print(df[numerical_cols].describe())

"""# --- 2.4. Menggabungkan Fitur Teks dan Pembersihan ---
karena konsep pendekatan TF-IDF yang kita gunakan maka kita harus mengabungkan fitur teks dan melakukan pembersihan terhdap fiturnya
"""

df['content'] = df['Review Text'] + ' ' + \
                df['Division Name'] + ' ' + \
                df['Department Name'] + ' ' + \
                df['Class Name']

def clean_text(text):
    text = str(text).lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    return text

df['content'] = df['content'].apply(clean_text)

print("\n--- Contoh Kolom 'content' Setelah Digabungkan dan Dibersihkan ---")
print(df[['Review Text', 'Division Name', 'Department Name', 'Class Name', 'content']].head())

"""# --- 2.5. Vektorisasi TF-IDF ---
memnafaatkan vektor tf-id yang nanti akan digunakan untuk proses pencarian menggunakan cos_similarity
"""

df_unique = df.drop_duplicates(subset='Clothing ID').reset_index(drop=True)

tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
tfidf_matrix = tfidf_vectorizer.fit_transform(df_unique['content'])

print(f"\nUkuran matriks TF-IDF: {tfidf_matrix.shape}")
print(f"Jumlah fitur (kata unik) yang digunakan: {len(tfidf_vectorizer.get_feature_names_out())}")

cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

print(f"\nUkuran matriks Cosine Similarity: {cosine_sim.shape}")
print("Contoh matriks Cosine Similarity (5x5 teratas):\n", cosine_sim[:5, :5])

cosine_sim_df = pd.DataFrame(cosine_sim, index=df_unique['Clothing ID'], columns=df_unique['Clothing ID'])

print("\n--- Contoh DataFrame Cosine Similarity ---")
print(cosine_sim_df.head())

cosine_sim_df.head()

"""# --- 3. Modeling untuk Rekomendasi  menggunakan Content-Based Filtering dengan pendekatan cosine similarity.  ---"""

def get_recommendations(clothing_id, cosine_sim_df, df, num_recommendations=10):

    if clothing_id not in cosine_sim_df.columns:
        print(f"Pakaian dengan ID {clothing_id} tidak ditemukan dalam dataset.")
        return pd.DataFrame()

    sim_scores_df = cosine_sim_df[[clothing_id]].copy()

    sim_scores_df = sim_scores_df.rename(columns={clothing_id: 'similarity'})

    sim_scores_df = sim_scores_df.drop(index=clothing_id, errors='ignore')

    sim_scores_df = sim_scores_df.sort_values(by='similarity', ascending=False)

    top_recommendations_ids = sim_scores_df.head(num_recommendations).index.tolist()

    recommended_items = df[df['Clothing ID'].isin(top_recommendations_ids)].drop_duplicates(subset=['Clothing ID'])
    recommended_items = recommended_items.set_index('Clothing ID').loc[top_recommendations_ids].reset_index()

    display_cols = ['Clothing ID', 'Division Name', 'Department Name', 'Class Name', 'Review Text', 'Rating']
    return recommended_items[display_cols]

"""# --- 4. Evaluasi   Model Rekomendasi dengan teknik Rekomendasi Similaritu  ---

# --- 4.1 Rekomendasi Similarity untuk Content Tertentu  ---
"""

example_clothing_id = df['Clothing ID'].iloc[0]
print(f"\n--- Mencari Rekomendasi untuk Clothing ID: {example_clothing_id} ---")

original_item = df[df['Clothing ID'] == example_clothing_id].drop_duplicates(subset=['Clothing ID'])
print("\nInformasi Pakaian Asli:")

print(original_item[['Clothing ID', 'Division Name', 'Department Name', 'Class Name', 'Review Text', 'Rating']].iloc[0])

recommendations = get_recommendations(example_clothing_id, cosine_sim_df, df, num_recommendations=5)

if not recommendations.empty:
    print(f"\nTop 5 Rekomendasi untuk Clothing ID {example_clothing_id}:")
    print(recommendations)
else:
    print(f"Tidak ada rekomendasi yang ditemukan untuk Clothing ID {example_clothing_id}.")

"""# --- 4.2 Rekomendasi Similarity untuk Content Populer  ---"""

popular_clothing_id = df['Clothing ID'].value_counts().index[0]
print(f"\n--- Mencari Rekomendasi untuk Clothing ID Paling Populer: {popular_clothing_id} ---")

original_item_popular = df[df['Clothing ID'] == popular_clothing_id].drop_duplicates(subset=['Clothing ID'])
print("\nInformasi Pakaian Asli:")
print(original_item_popular[['Clothing ID', 'Division Name', 'Department Name', 'Class Name', 'Review Text', 'Rating']].iloc[0])

recommendations_popular = get_recommendations(popular_clothing_id, cosine_sim_df, df, num_recommendations=5)

if not recommendations_popular.empty:
    print(f"\nTop 5 Rekomendasi untuk Clothing ID {popular_clothing_id}:")
    print(recommendations_popular)
else:
    print(f"Tidak ada rekomendasi yang ditemukan untuk Clothing ID {popular_clothing_id}.")

"""# --- 4.3  Evaluasi metric Demonstrasi Rekomendasi (NDCG)---"""

def dcg_at_k(relevances, k):
    """
    Menghitung Discounted Cumulative Gain (DCG) pada posisi k.
    Relevansi di sini diasumsikan sebagai rating item.
    """
    relevances = np.asarray(relevances, dtype='float64')[:k]
    if relevances.size == 0:
        return 0.
    return np.sum(relevances / np.log2(np.arange(2, relevances.size + 2)))

def idcg_at_k(relevances, k):
    """
    Menghitung Ideal Discounted Cumulative Gain (IDCG) pada posisi k.
    Relevansi diurutkan dari yang tertinggi untuk mendapatkan nilai ideal.
    """
    rrelevances = np.asarray(relevances, dtype='float64')[:k]
    if len(relevances) == 0:
        return 0.
    return dcg_at_k(np.sort(relevances)[::-1], k)

def ndcg_at_k(relevances, k):
    """
    Menghitung Normalized Discounted Cumulative Gain (nDCG) pada posisi k.
    nDCG = DCG / IDCG.
    """
    dcg_val = dcg_at_k(relevances, k)
    idcg_val = idcg_at_k(relevances, k)
    if idcg_val == 0:
        return 0.
    return dcg_val / idcg_val


num_recs_k = 5 # Jumlah rekomendasi untuk metrik

if not recommendations.empty:
    relevances = recommendations['Rating'].tolist()
    ndcg_score = ndcg_at_k(relevances, num_recs_k)
    print(f"\n--- Penilaian Metrik Kuantitatif untuk Rekomendasi baju tertentu dalam kasus ini ID 767 ---")
    print(f"nDCG@{num_recs_k} untuk rekomendasi ini: {ndcg_score:.4f}")

else:
    print(f"Tidak ada rekomendasi yang ditemukan untuk Clothing ID {example_clothing_id}.")


if not recommendations_popular.empty:

    relevances_popular = recommendations_popular['Rating'].tolist()
    ndcg_score_popular = ndcg_at_k(relevances_popular, num_recs_k)
    print(f"\n--- Penilaian Metrik Kuantitatif untuk Rekomendasi Populer ---")
    print(f"nDCG@{num_recs_k} untuk rekomendasi ini: {ndcg_score_popular:.4f}")
    print("Penjelasan nDCG@K sama seperti di atas.")

else:
    print(f"Tidak ada rekomendasi yang ditemukan untuk Clothing ID {popular_clothing_id}.")

"""* **Model rekomendasi khusus untuk ID 767** menghasilkan **nDCG\@5 = 0.9116**
* **Model rekomendasi populer (global/populer item)** menghasilkan **nDCG\@5 = 0.9139**

### Interpretasi:

* **nDCG (Normalized Discounted Cumulative Gain)** mengukur kualitas urutan hasil rekomendasi, dengan mempertimbangkan relevansi dan posisi item dalam daftar. Nilai mendekati 1 berarti urutan rekomendasi sangat baik.
* Dalam kasus ini, **rekomendasi populer sedikit mengungguli rekomendasi khusus untuk ID 767**.

### Analisis:

* **Perbedaan nDCG-nya sangat kecil** (0.0023), jadi bisa dibilang kedua pendekatan memiliki kualitas hampir setara dari sisi urutan relevansi.
* Namun, **rekomendasi populer cenderung seragam untuk semua user**, sedangkan rekomendasi personal (ID 767) seharusnya lebih disesuaikan dengan preferensi individual.
* Maka meskipun skor nDCG sedikit lebih rendah untuk rekomendasi personal, **ia mungkin tetap lebih relevan secara kontekstual untuk user ID 767**.

### Kesimpulan:

* Dari segi metrik kuantitatif, performa rekomendasi personal sudah **sangat kompetitif** terhadap baseline populer.
* Perlu dilihat aspek kualitatif (misal relevansi aktual item terhadap user, feedback pengguna, atau evaluasi manual) untuk menyimpulkan efektivitas nyata.
* Jika memungkinkan, bisa lanjut ke peningkatan model personalisasi agar **unggul signifikan dibanding rekomendasi populer**, karena saat ini keunggulannya belum terlihat secara jelas dari metrik kuantitatif saja.


"""